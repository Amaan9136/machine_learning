{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data by text to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amaan M k\\anaconda3\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import time\n",
    "\n",
    "def generate_audio_1(text_prompts, output_dir):\n",
    "  \"\"\"Generates audio data from text prompts and saves it with corresponding labels.\n",
    "\n",
    "  Args:\n",
    "    text_prompts: A list of text phrases or sentences. \n",
    "    output_dir: The directory where audio files and labels will be saved.\n",
    "  \"\"\"\n",
    "\n",
    "  if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "  # Open the labels file in append mode to avoid overwriting existing labels\n",
    "  with open(os.path.join(output_dir, \"labels.txt\"), \"a\") as label_file:\n",
    "    for i, text in enumerate(text_prompts):\n",
    "      tts = gTTS(text=text, lang='en')  # Change 'en' to your desired language\n",
    "      audio_file = f\"audio_{time.time()}.wav\"\n",
    "      # Save audio file\n",
    "      tts.save(os.path.join(output_dir, audio_file))\n",
    "      # Write label in the desired format\n",
    "      label_file.write(f\"{audio_file}: {text}\\n\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text_prompts = [\"Hello, how are you?\", \"I'm doing well, thanks.\", \"What's your name? can you speak few words\"]\n",
    "\n",
    "output_dir = \"data_training\"\n",
    "\n",
    "# Clear existing labels.txt (optional)\n",
    "if os.path.exists(os.path.join(output_dir, \"labels.txt\")):\n",
    "  os.remove(os.path.join(output_dir, \"labels.txt\"))\n",
    "\n",
    "generate_audio_1(text_prompts, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data by recording and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminate this running cell to stop\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not request results from Google Speech Recognition service; \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTerminate this running cell to stop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m generate_audio_2()\n",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m, in \u001b[0;36mgenerate_audio_2\u001b[1;34m(output_dir)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 17\u001b[0m         audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mlisten(source, phrase_time_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# Remove timeout\u001b[39;00m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# Recognize the speech\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio)\n",
      "File \u001b[1;32mc:\\Users\\Amaan M k\\anaconda3\\Lib\\site-packages\\speech_recognition\\__init__.py:491\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 491\u001b[0m buffer \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mread(source\u001b[38;5;241m.\u001b[39mCHUNK)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    493\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\Amaan M k\\anaconda3\\Lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaudio_stream\u001b[38;5;241m.\u001b[39mread(size, exception_on_overflow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Amaan M k\\anaconda3\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mread_stream(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def generate_audio_2(output_dir=\"data_training\"):\n",
    "    count = 0\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        while True:\n",
    "            try:\n",
    "                audio = recognizer.listen(source, phrase_time_limit=None)  # Remove timeout\n",
    "\n",
    "                # Recognize the speech\n",
    "                text = recognizer.recognize_google(audio)\n",
    "\n",
    "                # Save the audio file and label\n",
    "                audio_file = f\"audio_{time.time()}.wav\"\n",
    "                count += 1\n",
    "                print(f\"{count} Recording saved: {audio_file}: {text}\")\n",
    "                \n",
    "                with open(os.path.join(output_dir, \"labels.txt\"), \"a\") as label_file:\n",
    "                    label_file.write(f\"{audio_file}: {text}\\n\")\n",
    "\n",
    "                with open(os.path.join(output_dir, audio_file), \"wb\") as audio_file:\n",
    "                    audio_file.write(audio.get_wav_data())\n",
    "\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand audio\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "print(\"Terminate this running cell to stop\")\n",
    "generate_audio_2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
