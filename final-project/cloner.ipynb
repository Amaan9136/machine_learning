{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OOA_HDrke8fv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\0 AMAAN MAIN\\0 Course Notes\\Machine Learning - Udemy\\00 Machine Learning UDEMY A-Z (Codes and Datasets)\\00 my machine_learning\\final-project\\rtvc\\encoder\\audio.py:13: UserWarning: Unable to import 'webrtcvad'. This package enables noise removal and is recommended.\n",
            "  warn(\"Unable to import 'webrtcvad'. This package enables noise removal and is recommended.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded encoder \"encoder.pt\" trained to step 1564501\n",
            "Synthesizer using device: cpu\n",
            "Building Wave-RNN\n",
            "Trainable Parameters: 4.481M\n",
            "Loading model weights at rtvc\\saved_models\\vocoder\\vocoder.pt\n"
          ]
        }
      ],
      "source": [
        "# Initializing all the encoder libraries\n",
        "from IPython.display import Audio\n",
        "from IPython.utils import io\n",
        "import sys\n",
        "sys.path.append(\"rtvc\")\n",
        "from synthesizer.inference import Synthesizer\n",
        "from encoder import inference as encoder\n",
        "from vocoder import inference as vocoder\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import librosa\n",
        "encoder_weights = Path(\"rtvc/saved_models/encoder/encoder.pt\")\n",
        "vocoder_weights = Path(\"rtvc/saved_models/vocoder/vocoder.pt\")\n",
        "syn_dir = Path(\"rtvc/saved_models/synthesizer/synthesizer.pt\")\n",
        "encoder.load_model(encoder_weights)\n",
        "synthesizer = Synthesizer(syn_dir)\n",
        "vocoder.load_model(vocoder_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PEU1RADbwcaB"
      },
      "outputs": [],
      "source": [
        "text = \"Subscribe to the channel\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UKyRu-9XgYlT"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "resample() takes 1 positional argument but 3 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m in_fpath \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_training/audio_1724919320.2932997.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m reprocessed_wav \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mpreprocess_wav(in_fpath)\n\u001b[0;32m      3\u001b[0m original_wav, sampling_rate \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(in_fpath)\n\u001b[0;32m      4\u001b[0m preprocessed_wav \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mpreprocess_wav(original_wav, sampling_rate)\n",
            "File \u001b[1;32md:\\0 AMAAN MAIN\\0 Course Notes\\Machine Learning - Udemy\\00 Machine Learning UDEMY A-Z (Codes and Datasets)\\00 my machine_learning\\final-project\\rtvc\\encoder\\audio.py:42\u001b[0m, in \u001b[0;36mpreprocess_wav\u001b[1;34m(fpath_or_wav, source_sr, normalize, trim_silence)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Resample the wav if needed\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m source_sr \u001b[38;5;241m!=\u001b[39m sampling_rate:\n\u001b[1;32m---> 42\u001b[0m     wav \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mresample(wav, source_sr, sampling_rate)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Apply the preprocessing: normalize volume and shorten long silences \u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n",
            "\u001b[1;31mTypeError\u001b[0m: resample() takes 1 positional argument but 3 were given"
          ]
        }
      ],
      "source": [
        "in_fpath = Path(\"data_training/audio_1724919320.2932997.wav\")\n",
        "reprocessed_wav = encoder.preprocess_wav(in_fpath)\n",
        "original_wav, sampling_rate = librosa.load(in_fpath)\n",
        "preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
        "embed = encoder.embed_utterance(preprocessed_wav)\n",
        "with io.capture_output() as captured:\n",
        "  specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "generated_wav = vocoder.infer_waveform(specs[0])\n",
        "generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "display(Audio(generated_wav, rate=synthesizer.sample_rate))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
