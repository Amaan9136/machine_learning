{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer using device: cpu\n",
      "Error in embedding utterance: melspectrogram() takes 0 positional arguments but 2 positional arguments (and 2 keyword-only arguments) were given\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# Assuming rtvc is installed and accessible\n",
    "from synthesizer.inference import Synthesizer\n",
    "from encoder import inference as encoder\n",
    "from vocoder import inference as vocoder\n",
    "\n",
    "def load_models():\n",
    "    \"\"\"Loads the synthesizer model.\n",
    "\n",
    "    Returns:\n",
    "        Synthesizer: The loaded synthesizer model.\n",
    "    \"\"\"\n",
    "    synthesizer_model = Synthesizer('rtvc/saved_models/synthesizer/synthesizer.pt')\n",
    "    return synthesizer_model\n",
    "\n",
    "\n",
    "def convert_to_wav(input_file, output_file):\n",
    "    \"\"\"Converts an audio file to WAV format.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input audio file.\n",
    "        output_file (str): Path to the output WAV file.\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_file(input_file)\n",
    "    audio.export(output_file, format=\"wav\")\n",
    "\n",
    "\n",
    "def preprocess_wav(wav, source_sr, target_sr):\n",
    "    \"\"\"Preprocesses the WAV audio.\n",
    "\n",
    "    Args:\n",
    "        wav (np.ndarray): The audio data as a NumPy array.\n",
    "        source_sr (int): The sampling rate of the source audio.\n",
    "        target_sr (int): The target sampling rate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The preprocessed audio data.\n",
    "    \"\"\"\n",
    "    # Resample the wav if needed\n",
    "    if source_sr is not None and source_sr != target_sr:\n",
    "        wav = librosa.resample(y=wav, orig_sr=source_sr, target_sr=target_sr)\n",
    "    return wav\n",
    "\n",
    "\n",
    "def clone_voice_and_generate_text(synthesizer, audio_file, text):\n",
    "    \"\"\"Clones a voice and generates text using the cloned voice.\n",
    "\n",
    "    Args:\n",
    "        synthesizer (Synthesizer): The loaded synthesizer model.\n",
    "        audio_file (str): Path to the audio file containing the reference voice.\n",
    "        text (str): The text to be spoken with the cloned voice.\n",
    "    \"\"\"\n",
    "    # Convert audio file to WAV format\n",
    "    converted_audio_file = 'converted_audio.wav'\n",
    "    convert_to_wav(audio_file, converted_audio_file)\n",
    "\n",
    "    # Load and preprocess the reference audio file\n",
    "    try:\n",
    "        original_wav, sampling_rate = sf.read(converted_audio_file)\n",
    "        preprocessed_wav = preprocess_wav(original_wav, sampling_rate, synthesizer.sample_rate)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in loading or preprocessing audio file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Create the embedding for the voice\n",
    "    try:\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=preprocessed_wav, sr=synthesizer.sample_rate)\n",
    "        embed = encoder.embed_utterance(mel_spectrogram)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in embedding utterance: {e}\")\n",
    "        return\n",
    "\n",
    "    # Generate the speech from text using the cloned voice\n",
    "    try:\n",
    "        spectrogram = synthesizer.synthesize_spectrograms([text], [embed])[0]\n",
    "        generated_wav = vocoder.infer_waveform(spectrogram)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in generating speech: {e}\")\n",
    "        return\n",
    "\n",
    "    # Save or play the generated speech\n",
    "    output_file = \"output.wav\"\n",
    "    try:\n",
    "        sf.write(output_file, generated_wav, synthesizer.sample_rate)\n",
    "        print(f\"Generated speech saved as {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in saving audio file: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        generated_wav_audio = AudioSegment(\n",
    "            generated_wav.tobytes(),\n",
    "            frame_rate=synthesizer.sample_rate,\n",
    "            sample_width=generated_wav.dtype.itemsize,\n",
    "            channels=1\n",
    "        )\n",
    "        play(generated_wav_audio)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in playing audio: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    synthesizer = load_models()\n",
    "    audio_file = 'data_training/audio_1724919320.2932997.wav'\n",
    "    if os.path.exists(audio_file):\n",
    "        text = 'Hello, this is a cloned voice speaking!'\n",
    "        clone_voice_and_generate_text(synthesizer, audio_file, text)\n",
    "    else:\n",
    "        print(f\"Audio file does not exist: {audio_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file already exists: converted_audio.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import which\n",
    "\n",
    "# Set the path to ffmpeg and ffprobe\n",
    "ffmpeg_path = r\"C:\\Users\\Amaan M k\\anaconda3\\pkgs\\ffmpeg-4.2.2-he774522_0\\Library\\bin\\ffmpeg.exe\"\n",
    "ffprobe_path = r\"C:\\Users\\Amaan M k\\anaconda3\\pkgs\\ffmpeg-4.2.2-he774522_0\\Library\\bin\\ffprobe.exe\"\n",
    "\n",
    "# Update the paths in AudioSegment\n",
    "AudioSegment.converter = ffmpeg_path\n",
    "AudioSegment.ffprobe = ffprobe_path\n",
    "\n",
    "def convert_to_wav(input_file, output_file):\n",
    "    # Verify the existence of the input file\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Input file does not exist: {input_file}\")\n",
    "        return\n",
    "\n",
    "    # Check if the output file already exists\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Output file already exists: {output_file}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(input_file)\n",
    "        audio.export(output_file, format=\"wav\")\n",
    "        print(f\"Conversion successful: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting to WAV: {e}\")\n",
    "\n",
    "# Example usage\n",
    "audio_file = 'data_training/audio_1724919320.9108188.wav'\n",
    "converted_audio_file = 'converted_audio.wav'\n",
    "convert_to_wav(audio_file, converted_audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"rtvc\\saved_models/encoder/encoder.pt\" trained to step 1564501\n",
      "Synthesizer using device: cpu\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at rtvc\\saved_models/vocoder/vocoder.pt\n",
      "Failed to load encoder model. Please check the model file path or its integrity.\n",
      "Error cloning voice. Please check model loading and audio file.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play \n",
    "\n",
    "\n",
    "# Assuming rtvc is installed and accessible\n",
    "from synthesizer.inference import Synthesizer\n",
    "from encoder import inference as encoder\n",
    "from vocoder import inference as vocoder \n",
    "\n",
    "\n",
    "def load_models(rtvc_path=\"rtvc\"):\n",
    "  \"\"\"Loads the rtvc models from the specified path.\n",
    "\n",
    "  Args:\n",
    "      rtvc_path (str, optional): Path to the rtvc directory. Defaults to \"rtvc\".\n",
    "\n",
    "  Returns:\n",
    "      tuple: A tuple containing the loaded models (encoder, synthesizer, vocoder).\n",
    "  \"\"\"\n",
    "\n",
    "  if rtvc_path not in sys.path:\n",
    "    sys.path.append(rtvc_path)\n",
    "\n",
    "  try:\n",
    "    encoder_model = encoder.load_model(os.path.join(rtvc_path, \"saved_models/encoder/encoder.pt\"))\n",
    "  except Exception as e:\n",
    "    print(f\"Error loading encoder model: {e}\")\n",
    "    return None, None, None  # Return None for all models if loading fails\n",
    "\n",
    "  try:\n",
    "    synthesizer_model = Synthesizer(os.path.join(rtvc_path, \"saved_models/synthesizer/synthesizer.pt\"))\n",
    "  except Exception as e:\n",
    "    print(f\"Error loading synthesizer model: {e}\")\n",
    "    return None, None, None  # Return None for all models if loading fails\n",
    "\n",
    "  try:\n",
    "    vocoder_model = vocoder.load_model(os.path.join(rtvc_path, \"saved_models/vocoder/vocoder.pt\"))\n",
    "  except Exception as e:\n",
    "    print(f\"Error loading vocoder model: {e}\")\n",
    "    return None, None, None  # Return None for all models if loading fails\n",
    "\n",
    "  return encoder_model, synthesizer_model, vocoder_model\n",
    "\n",
    "\n",
    "def clone_voice(audio_path, text=\"Hello there\"):\n",
    "  \"\"\"Clones a voice from the input audio and speaks the specified text.\n",
    "\n",
    "  Args:\n",
    "      audio_path (str): Path to the audio file containing the voice to be cloned.\n",
    "      text (str, optional): The text to be spoken with the cloned voice. Defaults to \"Hello there\".\n",
    "\n",
    "  Returns:\n",
    "      AudioSegment: The generated audio with the cloned voice speaking the text,\n",
    "                     or None if there's an error.\n",
    "  \"\"\"\n",
    "\n",
    "  # Load and preprocess the input audio\n",
    "  audio, sr = librosa.load(audio_path)\n",
    "  mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "\n",
    "  # Load rtvc models\n",
    "  try:\n",
    "    encoder_model, synthesizer_model, vocoder_model = load_models()\n",
    "  except Exception as e:  # Catch potential errors during model loading\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    return None\n",
    "\n",
    "  # Check if encoder model is loaded correctly (removed unnecessary message)\n",
    "  if encoder_model is None:\n",
    "    # Provide more specific error message about encoder loading failure\n",
    "    print(\"Failed to load encoder model. Please check the model file path or its integrity.\")\n",
    "    return None\n",
    "\n",
    "  # Encode the mel spectrogram\n",
    "  encoded_features = encoder_model.infer(mel_spectrogram)\n",
    "\n",
    "  # Text-to-speech with cloned voice\n",
    "  mel_predicted = synthesizer_model.infer_text(text)\n",
    "\n",
    "  # Generate audio from the predicted mel spectrogram\n",
    "  generated_audio = vocoder_model.infer(mel_predicted)\n",
    "\n",
    "  # Convert generated audio data to a pydub AudioSegment\n",
    "  generated_audio = generated_audio.squeeze()  # Remove channel dimension if present\n",
    "  dub_audio = AudioSegment(np.float32(generated_audio) * 32767, frame_rate=sr, channels=1, sample_width=2)\n",
    "\n",
    "  return dub_audio\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  audio_path = \"data_training/audio_1724919320.2932997.wav\"  # Replace with your audio file path\n",
    "\n",
    "  try:\n",
    "    cloned_audio = clone_voice(audio_path)\n",
    "    if cloned_audio is not None:\n",
    "      print(\"Text-to-speech with cloned voice generated successfully!\")\n",
    "      play(cloned_audio)  # Play the generated audio\n",
    "    else:\n",
    "      print(\"Error cloning voice. Please check model loading and audio file.\")\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Error cloning voice: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
