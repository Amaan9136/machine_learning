{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unidecode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(rtvc_path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Import necessary modules\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msynthesizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Synthesizer\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mencoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inference \u001b[38;5;28;01mas\u001b[39;00m encoder\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inference \u001b[38;5;28;01mas\u001b[39;00m vocoder\n",
      "File \u001b[1;32md:\\0 AMAAN MAIN\\0 Course Notes\\Machine Learning - Udemy\\00 Machine Learning UDEMY A-Z (Codes and Datasets)\\00 my machine_learning\\final-project\\rtvc\\synthesizer\\inference.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msynthesizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtacotron\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tacotron\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msynthesizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbols\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m symbols\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msynthesizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_to_sequence\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simple_table\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "File \u001b[1;32md:\\0 AMAAN MAIN\\0 Course Notes\\Machine Learning - Udemy\\00 Machine Learning UDEMY A-Z (Codes and Datasets)\\00 my machine_learning\\final-project\\rtvc\\synthesizer\\utils\\text.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msynthesizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbols\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m symbols\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msynthesizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cleaners\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Mappings from symbol to numeric ID and vice versa:\u001b[39;00m\n",
      "File \u001b[1;32md:\\0 AMAAN MAIN\\0 Course Notes\\Machine Learning - Udemy\\00 Machine Learning UDEMY A-Z (Codes and Datasets)\\00 my machine_learning\\final-project\\rtvc\\synthesizer\\utils\\cleaners.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mCleaners are transformations that run over the input text at both training and eval time.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m     the symbols in symbols.py to match your data).\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munidecode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unidecode\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msynthesizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize_numbers\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Regular expression matching whitespace:\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'unidecode'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "rtvc_path = os.path.abspath('final-project/rtvc')\n",
    "if rtvc_path not in sys.path:\n",
    "    sys.path.append(rtvc_path)\n",
    "\n",
    "# Import necessary modules\n",
    "from synthesizer.inference import Synthesizer\n",
    "from encoder import inference as encoder\n",
    "from vocoder import inference as vocoder\n",
    "\n",
    "def load_models():\n",
    "    encoder.load_model('final-project/rtvc/encoder/saved_model.pt')\n",
    "    synthesizer_model = Synthesizer('final-project/rtvc/synthesizer/saved_model.pt')\n",
    "    vocoder.load_model('final-project/rtvc/vocoder/saved_model.pt')\n",
    "    return synthesizer_model\n",
    "\n",
    "def clone_voice_and_generate_text(synthesizer, audio_file, text):\n",
    "    # Load and preprocess the reference audio file\n",
    "    original_wav, sampling_rate = librosa.load(audio_file, sr=None)\n",
    "    preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
    "    \n",
    "    # Create the embedding for the voice\n",
    "    embed = encoder.embed_utterance(preprocessed_wav)\n",
    "    \n",
    "    # Generate the speech from text using the cloned voice\n",
    "    spectrogram = synthesizer.synthesize_spectrograms([text], [embed])[0]\n",
    "    generated_wav = vocoder.infer_waveform(spectrogram)\n",
    "    \n",
    "    # Normalize volume and convert to float32\n",
    "    generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
    "    generated_wav = encoder.preprocess_wav(generated_wav)\n",
    "    \n",
    "    # Save or play the generated speech\n",
    "    output_file = \"output.wav\"\n",
    "    sf.write(output_file, generated_wav, synthesizer.sample_rate)\n",
    "    print(f\"Generated speech saved as {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    synthesizer = load_models()\n",
    "    audio_file = 'data_training/audio_1724919320.2932997.wav'\n",
    "    text = 'Hello, this is a cloned voice speaking!'\n",
    "    clone_voice_and_generate_text(synthesizer, audio_file, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing contents of rtvc directory:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List contents of rtvc directory\n",
    "rtvc_dir = os.path.abspath('rtvc')\n",
    "print(\"Listing contents of rtvc directory:\")\n",
    "for root, dirs, files in os.walk(rtvc_dir):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'rtvc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Change directory to Real-Time-Voice-Cloning\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrtvc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Try import directly\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'rtvc'"
     ]
    }
   ],
   "source": [
    "# Change directory to Real-Time-Voice-Cloning\n",
    "os.chdir('rtvc')\n",
    "\n",
    "# Try import directly\n",
    "try:\n",
    "    from synthesizer.inference import Synthesizer\n",
    "    from encoder import inference as encoder\n",
    "    from vocoder import inference as vocoder\n",
    "    print(\"Modules imported successfully!\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"ModuleNotFoundError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Data collection and feature extraction\n",
    "def collect_data(target_voice_path):\n",
    "  audio, sr = librosa.load(target_voice_path)\n",
    "  mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "  return mfcc\n",
    "\n",
    "# Model training\n",
    "def train_model(training_data):\n",
    "  # Create a Variational Autoencoder (VAE) model\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(40, None)),  # Input shape (MFCCs)\n",
    "      tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "      tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "      tf.keras.layers.Dense(64),\n",
    "      tf.keras.layers.Lambda(lambda x: tf.keras.layers.experimental.preprocessing.Reshape(target_shape=(1, -1))(x)),\n",
    "      tf.keras.layers.Dense(40)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mse', optimizer='adam')\n",
    "  model.fit(training_data, training_data, epochs=100)\n",
    "  return model\n",
    "\n",
    "# Text-to-speech synthesis\n",
    "def synthesize_voice(model, text):\n",
    "  # Convert text to phonemes or characters\n",
    "  phonemes = convert_text_to_phonemes(text)\n",
    "\n",
    "  # Generate features using the trained model\n",
    "  features = model.predict(np.array([phonemes]))\n",
    "\n",
    "  # Synthesize audio using a vocoder or neural vocoder\n",
    "  audio = synthesize_audio_from_features(features)\n",
    "  return audio\n",
    "\n",
    "# Helper functions (implementations omitted for brevity)\n",
    "def convert_text_to_phonemes(text):\n",
    "  # ...\n",
    "  return phonemes\n",
    "\n",
    "def synthesize_audio_from_features(features):\n",
    "  # ...\n",
    "  return audio\n",
    "\n",
    "# Example usage\n",
    "target_voice_path = \"target_voice.wav\"\n",
    "training_data = collect_data(target_voice_path)\n",
    "model = train_model(training_data)\n",
    "\n",
    "text_to_clone = \"Hello, world!\"\n",
    "cloned_voice = synthesize_voice(model, text_to_clone)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
